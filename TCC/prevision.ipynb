{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.03728141057488232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\igorb\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#treinamento do modelo\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Carregar os dados financeiros de candles a partir de um arquivo CSV\n",
    "df = base\n",
    "\n",
    "# Pre-processar os dados\n",
    "# Eliminar valores ausentes\n",
    "df.dropna(inplace=True)\n",
    "# Codificação de categoria\n",
    "encoder = LabelEncoder()\n",
    "df.SYMBOL = encoder.fit_transform(df[['SYMBOL']])\n",
    "# Converter datas em variáveis numéricas\n",
    "df['DATE'] = pd.to_datetime(df['DATE'].apply(lambda x: datetime.datetime(x.year, x.month, x.day)))\n",
    "df['DATE'] = df['DATE'].astype('int64') / 10**9\n",
    "# Calcular o aumento de 10% apenas em relação ao preço de fechamento\n",
    "df['AUMENTO'] = (df['CLOSE'] / df['CLOSE'].shift(1) - 1) > 0.1\n",
    "# Normalizar as variáveis\n",
    "df_norm = (df - df.mean()) / df.std()\n",
    "# Eliminar a primeira linha, que não tem dados de aumento\n",
    "df_norm.dropna(inplace=True)\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X = df_norm.drop('AUMENTO', axis=1)\n",
    "y = df_norm['AUMENTO']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=100)\n",
    "\n",
    "# Treinar um modelo de regressão logística\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Salvar o modelo treinado\n",
    "joblib.dump(lr, 'modelo_treinado.pkl')\n",
    "\n",
    "# Avaliar o desempenho do modelo\n",
    "score = lr.score(X_test, y_test)\n",
    "print('Acurácia:', score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\igorb\\AppData\\Local\\Temp\\ipykernel_21072\\1042081369.py:31: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  base = pd.read_sql('SELECT * FROM bolsa_valores.cotacao where DATE >= DATE_SUB(CURDATE(), INTERVAL 24 MONTH)', conn)\n",
      "c:\\Users\\igorb\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1209/1209 [==============================] - 9s 6ms/step - loss: 0.0045\n",
      "Epoch 2/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0023\n",
      "Epoch 3/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0021\n",
      "Epoch 4/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0021\n",
      "Epoch 5/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0021\n",
      "Epoch 6/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0020\n",
      "Epoch 7/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0020\n",
      "Epoch 8/50\n",
      "1209/1209 [==============================] - 8s 7ms/step - loss: 0.0020\n",
      "Epoch 9/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0020\n",
      "Epoch 10/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0020\n",
      "Epoch 11/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0020\n",
      "Epoch 12/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0020\n",
      "Epoch 13/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0020\n",
      "Epoch 14/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0019\n",
      "Epoch 15/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0019\n",
      "Epoch 16/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0019\n",
      "Epoch 17/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0019\n",
      "Epoch 18/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0020\n",
      "Epoch 19/50\n",
      "1209/1209 [==============================] - 8s 7ms/step - loss: 0.0019\n",
      "Epoch 20/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0019\n",
      "Epoch 21/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0019\n",
      "Epoch 22/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0019\n",
      "Epoch 23/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0019\n",
      "Epoch 24/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0019\n",
      "Epoch 25/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0019\n",
      "Epoch 26/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0019\n",
      "Epoch 27/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0019\n",
      "Epoch 28/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0019\n",
      "Epoch 29/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0019\n",
      "Epoch 30/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0019\n",
      "Epoch 31/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0018\n",
      "Epoch 32/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0019\n",
      "Epoch 33/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0019\n",
      "Epoch 34/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0019\n",
      "Epoch 35/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0018\n",
      "Epoch 36/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0019\n",
      "Epoch 37/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0019\n",
      "Epoch 38/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0018\n",
      "Epoch 39/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0018\n",
      "Epoch 40/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0018\n",
      "Epoch 41/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0018\n",
      "Epoch 42/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0018\n",
      "Epoch 43/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0018\n",
      "Epoch 44/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0018\n",
      "Epoch 45/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0018\n",
      "Epoch 46/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0018\n",
      "Epoch 47/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0018\n",
      "Epoch 48/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0018\n",
      "Epoch 49/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0018\n",
      "Epoch 50/50\n",
      "1209/1209 [==============================] - 8s 6ms/step - loss: 0.0018\n",
      "303/303 [==============================] - 1s 3ms/step\n",
      "MSE: 0.0017192923358370785\n",
      "R2 Score: 0.979315665294779\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAÇÕES\n",
    "\n",
    "from consumidor import consumer, atualizacao_carteira\n",
    "from relatorio import analise_tecnica, grafico, noti_telegram\n",
    "import yfinance as yf\n",
    "import finplot as fplt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import datetime\n",
    "import pytz\n",
    "import os \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "\n",
    "# CONEXÃO COM BANCO DE DADOS\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "  host= os.getenv('host'),\n",
    "  user= os.getenv('user'),\n",
    "  password= os.getenv('password'),\n",
    "  database=\"bolsa_valores\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# ATUALIZAÇÃO DA BASE DE DADOS DE COTAÇÕES\n",
    "\n",
    "#consumer()\n",
    "\n",
    "base = pd.read_sql('SELECT * FROM bolsa_valores.cotacao where DATE >= DATE_SUB(CURDATE(), INTERVAL 24 MONTH)', conn)\n",
    "\n",
    "base\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Carregar os dados financeiros de candles a partir de um arquivo CSV\n",
    "df = base\n",
    "\n",
    "# Pre-processar os dados\n",
    "# Eliminar valores ausentes\n",
    "df.dropna(inplace=True)\n",
    "# Codificação de categoria\n",
    "encoder = LabelEncoder()\n",
    "df.SYMBOL = encoder.fit_transform(df[['SYMBOL']])\n",
    "# Converter datas em variáveis numéricas\n",
    "df['DATE'] = pd.to_datetime(df['DATE'].apply(lambda x: datetime.datetime(x.year, x.month, x.day)))\n",
    "df['DATE'] = df['DATE'].astype('int64') / 10**9\n",
    "# Calcular o aumento de 10% apenas em relação ao preço de fechamento\n",
    "df['AUMENTO'] = (df['CLOSE'] / df['CLOSE'].shift(1) - 1) > 0.1\n",
    "# Normalizar as variáveis\n",
    "df_norm = (df - df.mean()) / df.std()\n",
    "# Eliminar a primeira linha, que não tem dados de aumento\n",
    "df_norm.dropna(inplace=True)\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X = df_norm.drop('AUMENTO', axis=1)\n",
    "y = df_norm['AUMENTO']\n",
    "# Normalizar os dados\n",
    "scaler = MinMaxScaler()\n",
    "df_norm = pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index)\n",
    "\n",
    "# Definir janela de tempo para previsão\n",
    "window_size = 30\n",
    "\n",
    "# Criar função para gerar dados de treinamento e teste\n",
    "def create_train_test_data(data, window_size):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(window_size, len(data)):\n",
    "        X.append(data[i-window_size:i, :])\n",
    "        y.append(data[i, 0])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "# Gerar dados de treinamento e teste\n",
    "data = df_norm.to_numpy()\n",
    "X, y = create_train_test_data(data, window_size)\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_test, y_test = X[train_size:], y[train_size:]\n",
    "\n",
    "# Criar modelo de regressão com RNN LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(window_size, data.shape[1])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Treinar modelo\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "# Fazer previsões em dados de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliar desempenho do modelo\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R2 Score:\", r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>DIVIDENDS</th>\n",
       "      <th>AUMENTO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>0.360610</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.239881</td>\n",
       "      <td>0.239472</td>\n",
       "      <td>0.233368</td>\n",
       "      <td>0.226877</td>\n",
       "      <td>0.020881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17785</th>\n",
       "      <td>0.282940</td>\n",
       "      <td>0.561224</td>\n",
       "      <td>0.189028</td>\n",
       "      <td>0.188519</td>\n",
       "      <td>0.193736</td>\n",
       "      <td>0.188249</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25050</th>\n",
       "      <td>0.294036</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.356183</td>\n",
       "      <td>0.353669</td>\n",
       "      <td>0.349500</td>\n",
       "      <td>0.343423</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>0.381415</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.756518</td>\n",
       "      <td>0.755323</td>\n",
       "      <td>0.779208</td>\n",
       "      <td>0.759472</td>\n",
       "      <td>0.053035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39887</th>\n",
       "      <td>0.825243</td>\n",
       "      <td>0.683673</td>\n",
       "      <td>0.243932</td>\n",
       "      <td>0.247160</td>\n",
       "      <td>0.248603</td>\n",
       "      <td>0.241873</td>\n",
       "      <td>0.101369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DATE    SYMBOL      OPEN      HIGH       LOW     CLOSE    VOLUME  \\\n",
       "4128   0.360610  0.653061  0.239881  0.239472  0.233368  0.226877  0.020881   \n",
       "17785  0.282940  0.561224  0.189028  0.188519  0.193736  0.188249  0.005771   \n",
       "25050  0.294036  0.836735  0.356183  0.353669  0.349500  0.343423  0.003361   \n",
       "2657   0.381415  0.938776  0.756518  0.755323  0.779208  0.759472  0.053035   \n",
       "39887  0.825243  0.683673  0.243932  0.247160  0.248603  0.241873  0.101369   \n",
       "\n",
       "       DIVIDENDS  AUMENTO  \n",
       "4128         0.0      0.0  \n",
       "17785        0.0      0.0  \n",
       "25050        0.0      0.0  \n",
       "2657         0.0      0.0  \n",
       "39887        0.0      0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.12.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.12.0\n",
      "  Using cached tensorflow_intel-2.12.0-cp39-cp39-win_amd64.whl (272.8 MB)\n",
      "Collecting jax>=0.3.15\n",
      "  Using cached jax-0.4.8-py3-none-any.whl\n",
      "Collecting keras<2.13,>=2.12.0\n",
      "  Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (67.3.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.53.0-cp39-cp39-win_amd64.whl (4.0 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Collecting tensorboard<2.13,>=2.12\n",
      "  Using cached tensorboard-2.12.2-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.20.3)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.37.1)\n",
      "Collecting ml-dtypes>=0.0.3\n",
      "  Using cached ml_dtypes-0.1.0-cp39-cp39-win_amd64.whl (120 kB)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.9.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.8.1)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.3)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.12.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\igorb\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: opt-einsum, ml-dtypes, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, jax, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 gast-0.4.0 google-auth-2.17.3 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.53.0 jax-0.4.8 keras-2.12.0 ml-dtypes-0.1.0 opt-einsum-3.3.0 tensorboard-2.12.2 tensorflow-2.12.0 tensorflow-intel-2.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script google-oauthlib-tool.exe is installed in 'C:\\Users\\igorb\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\igorb\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts estimator_ckpt_converter.exe, import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\igorb\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilizar modelo treinado\n",
    "\n",
    "\n",
    "# Carregar o modelo treinado\n",
    "lr = joblib.load('modelo_treinado.pkl')\n",
    "\n",
    "\n",
    "# Pre-processar os dados\n",
    "# Converter datas em variáveis numéricas\n",
    "novos_dados['data'] = pd.to_datetime(novos_dados['data']).astype(int) / 10**9\n",
    "\n",
    "\n",
    "# Prever em quantos dias o preço da ação atingirá um aumento de pelo menos 10%\n",
    "novos_dados = pd.read_csv('novos_dados_candles.csv')\n",
    "novos_dados_norm = (novos_dados - df.mean()) / df.std()\n",
    "proba = lr.predict_proba(novos_dados_norm)\n",
    "idx = (proba[:, 1] > 0.5).argmax()\n",
    "dias = idx + 1\n",
    "print('O preço da ação atingirá um aumento de pelo menos 10% em', dias, 'dias.')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
